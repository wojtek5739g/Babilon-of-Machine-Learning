{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "calendar = pd.read_csv(\"../kaggle_forecasting_accuracy/calendar.csv\")\n",
    "sales_train_validation = pd.read_csv(\"../kaggle_forecasting_accuracy/sales_train_validation.csv\")\n",
    "sell_prices = pd.read_csv(\"../kaggle_forecasting_accuracy/sell_prices.csv\")\n",
    "\n",
    "original_sales_train_validation = sales_train_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58510310\n",
      "59364030\n"
     ]
    }
   ],
   "source": [
    "print(sales_train_validation.size)\n",
    "print(sales_train_evaluation.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3049\n"
     ]
    }
   ],
   "source": [
    "unique_products = sales_train_validation['item_id'].unique()\n",
    "print(len(unique_products))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "has_duplicates = sales_train_validation['item_id'].duplicated().any()\n",
    "print(has_duplicates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CALENDAR<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date  wm_yr_wk    weekday  wday  month  year       d  event_name_1 event_type_1  event_name_2 event_type_2  snap_CA  snap_TX  snap_WI\n",
      "0     2011-01-29     11101   Saturday     1      1  2011     d_1           NaN          NaN           NaN          NaN        0        0        0\n",
      "1     2011-01-30     11101     Sunday     2      1  2011     d_2           NaN          NaN           NaN          NaN        0        0        0\n",
      "2     2011-01-31     11101     Monday     3      1  2011     d_3           NaN          NaN           NaN          NaN        0        0        0\n",
      "3     2011-02-01     11101    Tuesday     4      2  2011     d_4           NaN          NaN           NaN          NaN        1        1        0\n",
      "4     2011-02-02     11101  Wednesday     5      2  2011     d_5           NaN          NaN           NaN          NaN        1        0        1\n",
      "...          ...       ...        ...   ...    ...   ...     ...           ...          ...           ...          ...      ...      ...      ...\n",
      "1964  2016-06-15     11620  Wednesday     5      6  2016  d_1965           NaN          NaN           NaN          NaN        0        1        1\n",
      "1965  2016-06-16     11620   Thursday     6      6  2016  d_1966           NaN          NaN           NaN          NaN        0        0        0\n",
      "1966  2016-06-17     11620     Friday     7      6  2016  d_1967           NaN          NaN           NaN          NaN        0        0        0\n",
      "1967  2016-06-18     11621   Saturday     1      6  2016  d_1968           NaN          NaN           NaN          NaN        0        0        0\n",
      "1968  2016-06-19     11621     Sunday     2      6  2016  d_1969  NBAFinalsEnd     Sporting  Father's day     Cultural        0        0        0\n",
      "\n",
      "[1969 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('expand_frame_repr', False)\n",
    "print(calendar)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SELL PRICES</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        store_id        item_id  wm_yr_wk  sell_price\n",
      "0           CA_1  HOBBIES_1_001     11325        9.58\n",
      "1           CA_1  HOBBIES_1_001     11326        9.58\n",
      "2           CA_1  HOBBIES_1_001     11327        8.26\n",
      "3           CA_1  HOBBIES_1_001     11328        8.26\n",
      "4           CA_1  HOBBIES_1_001     11329        8.26\n",
      "...          ...            ...       ...         ...\n",
      "6841116     WI_3    FOODS_3_827     11617        1.00\n",
      "6841117     WI_3    FOODS_3_827     11618        1.00\n",
      "6841118     WI_3    FOODS_3_827     11619        1.00\n",
      "6841119     WI_3    FOODS_3_827     11620        1.00\n",
      "6841120     WI_3    FOODS_3_827     11621        1.00\n",
      "\n",
      "[6841121 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sell_prices)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SALES TRAIN VALIDATION</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  id        item_id    dept_id   cat_id store_id state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  d_1909  d_1910  d_1911  d_1912  d_1913\n",
      "0      HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0  ...       1       3       0       1       1       1       3       0       1       1\n",
      "1      HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0  ...       0       0       0       0       0       1       0       0       0       0\n",
      "2      HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0  ...       2       1       2       1       1       1       0       1       1       1\n",
      "3      HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0  ...       1       0       5       4       1       0       1       3       7       2\n",
      "4      HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0  ...       2       1       1       0       1       1       2       2       2       4\n",
      "...                              ...            ...        ...      ...      ...      ...  ...  ...  ...  ...  ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...\n",
      "30485    FOODS_3_823_WI_3_validation    FOODS_3_823    FOODS_3    FOODS     WI_3       WI    0    0    2    2  ...       2       0       0       0       0       0       1       0       0       1\n",
      "30486    FOODS_3_824_WI_3_validation    FOODS_3_824    FOODS_3    FOODS     WI_3       WI    0    0    0    0  ...       0       0       0       0       0       0       0       0       1       0\n",
      "30487    FOODS_3_825_WI_3_validation    FOODS_3_825    FOODS_3    FOODS     WI_3       WI    0    6    0    2  ...       2       1       0       2       0       1       0       0       1       0\n",
      "30488    FOODS_3_826_WI_3_validation    FOODS_3_826    FOODS_3    FOODS     WI_3       WI    0    0    0    0  ...       0       0       1       0       0       1       0       3       1       3\n",
      "30489    FOODS_3_827_WI_3_validation    FOODS_3_827    FOODS_3    FOODS     WI_3       WI    0    0    0    0  ...       0       0       0       0       0       0       0       0       0       0\n",
      "\n",
      "[30490 rows x 1919 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sales_train_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_train_validation = sales_train_validation.drop(['id'], axis = 1) \n",
    "sales_train_validation = sales_train_validation.iloc[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_1</th>\n",
       "      <th>d_2</th>\n",
       "      <th>d_3</th>\n",
       "      <th>d_4</th>\n",
       "      <th>d_5</th>\n",
       "      <th>d_6</th>\n",
       "      <th>d_7</th>\n",
       "      <th>d_8</th>\n",
       "      <th>d_9</th>\n",
       "      <th>d_10</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1904</th>\n",
       "      <th>d_1905</th>\n",
       "      <th>d_1906</th>\n",
       "      <th>d_1907</th>\n",
       "      <th>d_1908</th>\n",
       "      <th>d_1909</th>\n",
       "      <th>d_1910</th>\n",
       "      <th>d_1911</th>\n",
       "      <th>d_1912</th>\n",
       "      <th>d_1913</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30486</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30487</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30488</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30489</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30490 rows × 1913 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       d_1  d_2  d_3  d_4  d_5  d_6  d_7  d_8  d_9  d_10  ...  d_1904  d_1905  d_1906  d_1907  d_1908  d_1909  d_1910  d_1911  d_1912  d_1913\n",
       "0        0    0    0    0    0    0    0    0    0     0  ...       1       3       0       1       1       1       3       0       1       1\n",
       "1        0    0    0    0    0    0    0    0    0     0  ...       0       0       0       0       0       1       0       0       0       0\n",
       "2        0    0    0    0    0    0    0    0    0     0  ...       2       1       2       1       1       1       0       1       1       1\n",
       "3        0    0    0    0    0    0    0    0    0     0  ...       1       0       5       4       1       0       1       3       7       2\n",
       "4        0    0    0    0    0    0    0    0    0     0  ...       2       1       1       0       1       1       2       2       2       4\n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...\n",
       "30485    0    0    2    2    0    3    1    4    1     0  ...       2       0       0       0       0       0       1       0       0       1\n",
       "30486    0    0    0    0    0    5    0    1    1     3  ...       0       0       0       0       0       0       0       0       1       0\n",
       "30487    0    6    0    2    2    4    1    8    5     2  ...       2       1       0       2       0       1       0       0       1       0\n",
       "30488    0    0    0    0    0    0    0    0    0     0  ...       0       0       1       0       0       1       0       3       1       3\n",
       "30489    0    0    0    0    0    0    0    0    0     0  ...       0       0       0       0       0       0       0       0       0       0\n",
       "\n",
       "[30490 rows x 1913 columns]"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_train_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MakeTrainAndValidateExamples(example):\n",
    "    cut_index = int(len(example)*0.8)\n",
    "\n",
    "    df_train = example.iloc[:cut_index]\n",
    "    df_validate = example.iloc[cut_index:]\n",
    "\n",
    "\n",
    "    return df_train, df_validate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>RANDOM FOREST REGRESSION</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sequencing datasets</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SequencingDatasets(dataset):  \n",
    "    dataset_seqs = []\n",
    "    dataset_targets = []\n",
    "    sequence_len = 30\n",
    "    for i in range(len(dataset)-sequence_len-1):\n",
    "        # print(np.array(dataset.iloc[i:i+sequence_len]))\n",
    "        dataset_seqs.append(np.array(dataset.iloc[i:i+sequence_len]))\n",
    "        dataset_targets.append(dataset.iloc[i+sequence_len+1])\n",
    "    dataset_seqs = np.asarray(dataset_seqs)\n",
    "    dataset_targets = np.asarray(dataset_targets)\n",
    "\n",
    "    return dataset_seqs, dataset_targets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Time series</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # przygotowanie danych\n",
    "# train_set, validate_set = MakeTrainAndValidateExamples(sales_train_validation.iloc[0])\n",
    "# train_targets = train_set.values\n",
    "# validate_targets = validate_set.values\n",
    "\n",
    "# # konwertowanie danych na szeregi czasowe\n",
    "# start_date = '2011-01-29'\n",
    "# end_date = '2016-06-19'\n",
    "# date_range = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "# train_series = pd.Series(train_targets, index=date_range[:len(train_targets)])\n",
    "# last_value = train_series[-1]\n",
    "# extra_values = pd.Series([last_value] * (len(validate_series) - 1), index=validate_series.index[1:])\n",
    "# validate_series = pd.concat([pd.Series([last_value]), extra_values])\n",
    "\n",
    "# # dopasowanie modelu ARIMA\n",
    "# model = ARIMA(train_series, order=(3, 1, 2)) # przykładowe wartości parametrów (p,d,q)\n",
    "# model_fit = model.fit()\n",
    "\n",
    "# # prognozowanie na zbiorze walidacyjnym\n",
    "# test_predicted = model_fit.forecast(steps=len(validate_series))\n",
    "\n",
    "# # obliczenie błędu średniokwadratowego\n",
    "# test_mse = mean_squared_error(validate_series, test_predicted)\n",
    "# test_r2 = r2_score(validate_series[:-1], test_predicted[:-1])\n",
    "\n",
    "# print(f'Test Mean squared error: {test_mse:.2f}')\n",
    "# print(f'Test R-squared: {test_r2:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(sales_train_validation_item_for_state_shop):\n",
    "    # przygotowanie danych\n",
    "    train_set, validate_set = MakeTrainAndValidateExamples(sales_train_validation_item_for_state_shop)\n",
    "    train_seqs, train_targets = SequencingDatasets(train_set)\n",
    "    validate_seqs, validate_targets = SequencingDatasets(validate_set)\n",
    "\n",
    "    # definiowanie modelu\n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "    # zdefiniowanie zakresu hiperparametrów do przeszukania\n",
    "    param_grid = {'n_estimators': [64, 74, 84, 94, 104, 114, 120],\n",
    "                  'max_features': ['sqrt', 'log2'],\n",
    "                  'max_depth': [None, 5, 10, 20],\n",
    "                  'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "    # zdefiniowanie metryki\n",
    "    scoring = 'neg_mean_squared_error'\n",
    "\n",
    "    # przeszukanie siatki hiperparametrów\n",
    "    grid_search = GridSearchCV(rf_model, param_grid, scoring=scoring, cv=5)\n",
    "    grid_search.fit(train_seqs, train_targets)\n",
    "\n",
    "    # wybór najlepszego modelu\n",
    "    best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "    # dokładność modelu na zbiorze walidacyjnym\n",
    "    test_predicted = best_rf_model.predict(validate_seqs)\n",
    "    test_predicted_rounded = [round(x) for x in test_predicted]\n",
    "    test_rmse = mean_squared_error(validate_targets, test_predicted, squared=False)\n",
    "    test_rmse_rounded = mean_squared_error(validate_targets, test_predicted_rounded, squared=False)\n",
    "    print(f'Test Root Mean squared error: {test_rmse:.2f}')\n",
    "    print(f'Test Root Mean squared error for rounded values: {test_rmse_rounded:.2f}')\n",
    "\n",
    "    return test_rmse, test_predicted, validate_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validate_targets:  [0 0 0 0 1 0 0 0 1 0 3 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 2 1 0 0 0 0 0\n",
      " 1 0 0 1 1 0 2 0 2 1 0 1 0 0 0 2 1 1 1 0 0 0 1 0 1 0 0 0 1 0 0 1 1 0 0 0 3\n",
      " 4 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 0 0 0 0 0 0 0 2 1 0 0 1 0\n",
      " 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 1 0 2 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 1\n",
      " 1 0 0 0 0 0 1 0 1 1 0 3 0 0 0 0 0 0 0 1 0 0 0 0 0 2 1 0 0 1 1 0 2 0 1 0 2\n",
      " 1 1 5 0 1 0 3 5 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      "predicted [0.18902887 0.22705928 0.19567049 0.22066609 0.22768272 0.20398976\n",
      " 0.2187102  0.23332251 0.2064477  0.23376789 0.19752502 0.24499454\n",
      " 0.42583198 0.29552626 0.38897198 0.38327027 0.35697224 0.29855091\n",
      " 0.33779662 0.23760603 0.21353    0.22616317 0.25271322 0.3048778\n",
      " 0.20776829 0.24183825 0.23773458 0.22916494 0.25048415 0.23230221\n",
      " 0.26755288 0.22228582 0.23446882 0.26648482 0.18854001 0.21362843\n",
      " 0.21231042 0.22970986 0.20300737 0.25346968 0.23171338 0.29158158\n",
      " 0.21604498 0.22336908 0.2086816  0.26654772 0.22883513 0.22632401\n",
      " 0.22725372 0.2133099  0.20293143 0.21806688 0.2430701  0.23619647\n",
      " 0.22411877 0.20339137 0.20275242 0.1923649  0.20722143 0.22158696\n",
      " 0.23972393 0.21863684 0.24873536 0.23391689 0.25472003 0.25706316\n",
      " 0.21393164 0.21349507 0.21291962 0.41798121 0.27104322 0.27437665\n",
      " 0.30147919 0.28197028 0.23326821 0.23483596 0.23656944 0.25073552\n",
      " 0.2384396  0.29345056 0.29810543 0.21511223 0.50270986 0.37997722\n",
      " 0.6189586  0.4088573  0.24291655 0.30298249 0.48446748 0.2427073\n",
      " 0.28854093 0.32049952 0.31482933 0.30880618 0.30524096 0.41815864\n",
      " 0.35832541 0.34490055 0.2794308  0.28389639 0.264235   0.26679368\n",
      " 0.312296   0.33204028 0.19452761 0.23805891 0.25661803 0.33057841\n",
      " 0.24615847 0.35467581 0.23805711 0.28996852 0.70017532 0.63650806\n",
      " 0.68499968 0.53353156 0.35589771 0.33043456 0.31050069 0.39466504\n",
      " 0.31189666 0.23170435 0.27989979 0.33499144 0.27456615 0.2222365\n",
      " 0.22270718 0.29514772 0.2505043  0.22612582 0.24816692 0.25835397\n",
      " 0.2530905  0.2500403  0.43292681 0.28453062 0.22608949 0.23742924\n",
      " 0.2349967  0.27979564 0.26216872 0.25045889 0.21447829 0.19861005\n",
      " 0.41128821 0.31681043 0.27658222 0.24314085 0.28212385 0.25310612\n",
      " 0.25328456 0.23544954 0.22054703 0.23853978 0.24449545 0.24541427\n",
      " 0.23472189 0.61707691 0.38205797 0.38280107 0.38680325 0.3014916\n",
      " 0.27451903 0.33068868 0.23683791 0.19437553 0.1980125  0.22212582\n",
      " 0.25367457 0.21193451 0.38981544 0.41873728 0.24992596 0.28583829\n",
      " 0.29605759 0.2708999  0.32710556 0.2538231  0.23524958 0.23507766\n",
      " 0.22348661 0.26751572 0.23150458 0.28108249 0.31970985 0.25628291\n",
      " 0.24309924 0.23744358 0.26664834 0.28539652 0.24801968 0.23326733\n",
      " 0.22437962 0.2104319  0.25307074 0.27936346 0.27899215 0.28060931\n",
      " 0.59370588 0.27932843 0.38014312 0.33436905 0.4146289  0.31313217\n",
      " 0.29774681 0.23593821 0.22792869 0.25424399 0.29473261 0.30211728\n",
      " 0.24398664 0.24612244 0.34859562 0.33601308 0.29896764 0.26353158\n",
      " 0.37623822 0.22758243 0.33141395 0.37175675 0.38084085 0.34357477\n",
      " 0.30433967 0.58420869 0.50644628 0.49874839 0.60987375 0.69057494\n",
      " 0.60730736 0.58892756 0.7367202  0.86284574 0.75152907 0.53423127\n",
      " 0.42938375 0.41407462 0.48425457 0.42906643 0.27652236 0.26699852\n",
      " 0.36693587 0.28404806 0.33780744 0.24225994 0.22693543 0.24820149\n",
      " 0.28079126 0.50665958 0.36059738 0.26106812 0.35707477 0.23475414\n",
      " 0.51684655 0.23324214 0.24534887 0.2623395  0.2218178  0.23401917\n",
      " 0.23199959 0.22923744 0.21847464 0.24466542 0.19888412 0.20039977\n",
      " 0.19963423 0.19470631 0.1955207  0.21005121 0.20372255 0.19891787\n",
      " 0.19951342 0.23019777 0.19634382 0.21875047 0.24324881 0.20333133\n",
      " 0.18688713 0.19913151 0.2100409  0.21028048 0.25110191 0.20016507\n",
      " 0.20457523 0.22382506 0.2097874  0.21430306 0.20762068 0.19477385\n",
      " 0.21819592 0.17997328 0.22048141 0.20753235 0.22591424 0.24199487\n",
      " 0.19985617 0.21279011 0.20533852 0.25274001 0.19674977 0.2202623\n",
      " 0.19319451 0.19378674 0.21836877 0.21601731 0.26318637 0.19717023\n",
      " 0.215814   0.21616631 0.24096092 0.25675992 0.21844412 0.24741976\n",
      " 0.22916036 0.22008486 0.21004947 0.22685585 0.23012317 0.19930128\n",
      " 0.2287879  0.21219646 0.2078616  0.22266307 0.19326173 0.22774644\n",
      " 0.21531004 0.24174284 0.2480923  0.25225845 0.2548245  0.22669092\n",
      " 0.23289214 0.26579616 0.21582835 0.22281141 0.23457188 0.24058331\n",
      " 0.20827695 0.24917906 0.19887954 0.21311035 0.20576208 0.2038766\n",
      " 0.19132495 0.19868245 0.20263274 0.18968857 0.18806554 0.19702204\n",
      " 0.20131271 0.24677361 0.25133376 0.25383559]\n",
      "MSE:  0.59375\n",
      "r2:  -0.1571844278411325\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(validate_targets, test_predicted_rounded)\n",
    "print(\"validate_targets: \", validate_targets)\n",
    "print(\"predicted\", test_predicted)\n",
    "print(\"MSE: \", mse)\n",
    "print(\"r2: \", r2 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Rozdzielenie dataframe'u na oddzielne dla każdego stanu i dla każdego sklepu</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_by_state_and_store = {}\n",
    "for state, group in original_sales_train_validation.groupby(\"state_id\"):\n",
    "    dataframes_by_store = {}\n",
    "    for store, dataframe in group.groupby(\"store_id\"):\n",
    "        dataframes_by_store[store] = dataframe\n",
    "    dataframes_by_state_and_store[state] = dataframes_by_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 id        item_id    dept_id   cat_id store_id state_id  d_1  d_2  d_3  d_4  ...  d_1904  d_1905  d_1906  d_1907  d_1908  d_1909  d_1910  d_1911  d_1912  d_1913\n",
      "0     HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0  ...       1       3       0       1       1       1       3       0       1       1\n",
      "1     HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0  ...       0       0       0       0       0       1       0       0       0       0\n",
      "2     HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0  ...       2       1       2       1       1       1       0       1       1       1\n",
      "3     HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0  ...       1       0       5       4       1       0       1       3       7       2\n",
      "4     HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1       CA    0    0    0    0  ...       2       1       1       0       1       1       2       2       2       4\n",
      "...                             ...            ...        ...      ...      ...      ...  ...  ...  ...  ...  ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...\n",
      "3044    FOODS_3_823_CA_1_validation    FOODS_3_823    FOODS_3    FOODS     CA_1       CA    0    0    0    0  ...       4       0       2       1       0       2       0       4       1       1\n",
      "3045    FOODS_3_824_CA_1_validation    FOODS_3_824    FOODS_3    FOODS     CA_1       CA    1    0    5    0  ...       1       0       0       0       1       0       2       2       1       0\n",
      "3046    FOODS_3_825_CA_1_validation    FOODS_3_825    FOODS_3    FOODS     CA_1       CA    0    0    0    0  ...       1       2       0       0       1       1       0       1       3       2\n",
      "3047    FOODS_3_826_CA_1_validation    FOODS_3_826    FOODS_3    FOODS     CA_1       CA    0    0    0    0  ...       1       0       4       0       2       0       0       3       2       0\n",
      "3048    FOODS_3_827_CA_1_validation    FOODS_3_827    FOODS_3    FOODS     CA_1       CA    0    0    0    0  ...       5       5      19      14       0       3       3       5       3      21\n",
      "\n",
      "[3049 rows x 1919 columns]\n"
     ]
    }
   ],
   "source": [
    "ca_1_dataframe = dataframes_by_state_and_store['CA']['CA_1']\n",
    "print(ca_1_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HOBBIES_1_001' 'HOBBIES_1_002' 'HOBBIES_1_003' ... 'FOODS_3_825'\n",
      " 'FOODS_3_826' 'FOODS_3_827']\n",
      "3049\n"
     ]
    }
   ],
   "source": [
    "unique_values = ca_1_dataframe[\"item_id\"].unique()\n",
    "print(unique_values)\n",
    "print(len(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30490\n"
     ]
    }
   ],
   "source": [
    "total_rows = 0\n",
    "\n",
    "for state in dataframes_by_state_and_store:\n",
    "    for store in dataframes_by_state_and_store[state]:\n",
    "        total_rows += len(dataframes_by_state_and_store[state][store])\n",
    "        \n",
    "print(total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in dataframes_by_state_and_store:\n",
    "    for store in dataframes_by_state_and_store[state]:\n",
    "        dataframes_by_state_and_store[state][store] = dataframes_by_state_and_store[state][store].drop(['id'], axis = 1) \n",
    "        # dataframes_by_state_and_store[state][store] = dataframes_by_state_and_store[state][store].iloc[:, [0] + list(range(5, len(dataframes_by_state_and_store[state][store].columns)))]\n",
    "        dataframes_by_state_and_store[state][store] = dataframes_by_state_and_store[state][store].iloc[:, 5:]\n",
    "        dataframes_by_state_and_store[state][store] = dataframes_by_state_and_store[state][store].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klucz: CA, ilość wartości: 4\n",
      "Klucz: TX, ilość wartości: 3\n",
      "Klucz: WI, ilość wartości: 3\n"
     ]
    }
   ],
   "source": [
    "for key in dataframes_by_state_and_store:\n",
    "    print(f\"Klucz: {key}, ilość wartości: {len(dataframes_by_state_and_store[key])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      d_1  d_2  d_3  d_4  d_5  d_6  d_7  d_8  d_9  d_10  ...  d_1904  d_1905  d_1906  d_1907  d_1908  d_1909  d_1910  d_1911  d_1912  d_1913\n",
      "0       0    0    0    0    0    0    0    0    0     0  ...       1       3       0       1       1       1       3       0       1       1\n",
      "1       0    0    0    0    0    0    0    0    0     0  ...       0       0       0       0       0       1       0       0       0       0\n",
      "2       0    0    0    0    0    0    0    0    0     0  ...       2       1       2       1       1       1       0       1       1       1\n",
      "3       0    0    0    0    0    0    0    0    0     0  ...       1       0       5       4       1       0       1       3       7       2\n",
      "4       0    0    0    0    0    0    0    0    0     0  ...       2       1       1       0       1       1       2       2       2       4\n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...   ...  ...     ...     ...     ...     ...     ...     ...     ...     ...     ...     ...\n",
      "3044    0    0    0    0    0    0    0    0    0     0  ...       4       0       2       1       0       2       0       4       1       1\n",
      "3045    1    0    5    0    0    3    0    0    2     1  ...       1       0       0       0       1       0       2       2       1       0\n",
      "3046    0    0    0    0    0    0    0    1    2     1  ...       1       2       0       0       1       1       0       1       3       2\n",
      "3047    0    0    0    0    0    0    0    0    0     0  ...       1       0       4       0       2       0       0       3       2       0\n",
      "3048    0    0    0    0    0    0    0    0    0     0  ...       5       5      19      14       0       3       3       5       3      21\n",
      "\n",
      "[3049 rows x 1913 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataframes_by_state_and_store['CA'][\"CA_1\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>1 przedmiot w jednym stanie i wszystkich sklepach w tym stanie</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[659], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m state\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCA\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m store \u001b[39min\u001b[39;00m dataframes_by_state_and_store[state]:\n\u001b[0;32m      8\u001b[0m     \n\u001b[0;32m      9\u001b[0m     \u001b[39m# wywołanie funkcji train() dla każdego sklepu\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     rmse, test_predicted, validate_targets \u001b[39m=\u001b[39m train(dataframes_by_state_and_store[\u001b[39m'\u001b[39;49m\u001b[39mCA\u001b[39;49m\u001b[39m'\u001b[39;49m][store]\u001b[39m.\u001b[39;49miloc[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m     12\u001b[0m     \u001b[39m# dodanie wyniku RMSE do listy\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     rmse_list\u001b[39m.\u001b[39mappend(rmse)\n",
      "Cell \u001b[1;32mIn[650], line 21\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(sales_train_validation_item_for_state_shop)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39m# przeszukanie siatki hiperparametrów\u001b[39;00m\n\u001b[0;32m     20\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(rf_model, param_grid, scoring\u001b[39m=\u001b[39mscoring, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(train_seqs, train_targets)\n\u001b[0;32m     23\u001b[0m \u001b[39m# wybór najlepszego modelu\u001b[39;00m\n\u001b[0;32m     24\u001b[0m best_rf_model \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1387\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1388\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    462\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[0;32m    463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m    464\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    465\u001b[0m ]\n\u001b[0;32m    467\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    468\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    472\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 473\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m    474\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m    475\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    476\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    477\u001b[0m )(\n\u001b[0;32m    478\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    479\u001b[0m         t,\n\u001b[0;32m    480\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[0;32m    481\u001b[0m         X,\n\u001b[0;32m    482\u001b[0m         y,\n\u001b[0;32m    483\u001b[0m         sample_weight,\n\u001b[0;32m    484\u001b[0m         i,\n\u001b[0;32m    485\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[0;32m    486\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    487\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[0;32m    488\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[0;32m    489\u001b[0m     )\n\u001b[0;32m    490\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[0;32m    491\u001b[0m )\n\u001b[0;32m    493\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\sklearn\\utils\\parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    121\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    122\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    182\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[1;32m--> 184\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    185\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\sklearn\\tree\\_classes.py:1247\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1219\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1245\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m   1248\u001b[0m         X,\n\u001b[0;32m   1249\u001b[0m         y,\n\u001b[0;32m   1250\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1251\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[0;32m   1252\u001b[0m     )\n\u001b[0;32m   1253\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32me:\\Studia\\hackathon\\my_env\\lib\\site-packages\\sklearn\\tree\\_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    370\u001b[0m         splitter,\n\u001b[0;32m    371\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    377\u001b[0m     )\n\u001b[1;32m--> 379\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[0;32m    381\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    382\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tworzenie pustej listy do przechowywania wyników RMSE\n",
    "rmse_list = []\n",
    "\n",
    "# iteracja po wszystkich sklepach w stanie CA\n",
    "\n",
    "state='CA'\n",
    "for store in dataframes_by_state_and_store[state]:\n",
    "    \n",
    "    # wywołanie funkcji train() dla każdego sklepu\n",
    "    rmse, test_predicted, validate_targets = train(dataframes_by_state_and_store['CA'][store].iloc[0])\n",
    "    \n",
    "    # dodanie wyniku RMSE do listy\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "    print(f'Predicted values for store {store} in {state}: ', test_predicted)\n",
    "    print(f'Real values for store {store} in {state}: '. validate_targets)\n",
    "\n",
    "# obliczenie średniej RMSE dla stanu CA\n",
    "avg_rmse = sum(rmse_list) / len(rmse_list)\n",
    "print(f\"Średnia RMSE dla stanu CA: {avg_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes_by_state_and_store['CA']['CA_1'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    train(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
